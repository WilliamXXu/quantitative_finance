{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70127cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "from typing import Dict, Union, Tuple, Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example of how to use the function\n",
    "#     # Assuming you have a dictionary like this:\n",
    "#     # stock_data = {\n",
    "#     #     'AAPL': dataframe_with_multiindex_columns,\n",
    "#     #     'GOOGL': dataframe_with_multiindex_columns,\n",
    "#     #     'MSFT': dataframe_with_multiindex_columns\n",
    "#     # }\n",
    "    \n",
    "#     # Create correlation network for last 30 days\n",
    "#     # G = create_stock_correlation_network(stock_data, n_days=30, correlation_threshold=0.3)\n",
    "    \n",
    "#     # Analyze the network\n",
    "#     # analysis = analyze_correlation_network(G)\n",
    "#     # print(analysis)\n",
    "    \n",
    "#     # Visualize (requires matplotlib and networkx)\n",
    "#     # import matplotlib.pyplot as plt\n",
    "#     # pos = nx.spring_layout(G)\n",
    "#     # edge_weights = [G[u][v]['correlation'] for u, v in G.edges()]\n",
    "#     # nx.draw(G, pos, with_labels=True, edge_color=edge_weights, \n",
    "#     #         edge_cmap=plt.cm.RdYlBu, node_color='lightblue')\n",
    "#     # plt.show()\n",
    "    \n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_change(k): \n",
    "    return np.log(k).diff() \n",
    "def pct_change(k):\n",
    "    return k.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _organise_price_data(stock_data_dict, n_days):\n",
    "        # Extract close prices for all stocks\n",
    "    price_data = {}\n",
    "    \n",
    "    for stock_symbol, df in stock_data_dict.items():\n",
    "        try:\n",
    "            # Get the 'Close' price column for this stock\n",
    "            if ('Close', stock_symbol) in df.columns:\n",
    "                close_prices = df[('Close', stock_symbol)]\n",
    "            elif 'Close' in df.columns:\n",
    "                # Handle case where there might be a single-level index\n",
    "                close_prices = df['Close']\n",
    "            else:\n",
    "                print(f\"Warning: No 'Close' price found for {stock_symbol}\")\n",
    "                continue\n",
    "                \n",
    "            # Get last n days of data\n",
    "            recent_prices = close_prices.tail(n_days)\n",
    "            \n",
    "            # Only include if we have enough data points\n",
    "            if len(recent_prices) >= min(n_days, 2):\n",
    "                price_data[stock_symbol] = recent_prices\n",
    "            else:\n",
    "                print(f\"Warning: Insufficient data for {stock_symbol} (only {len(recent_prices)} days)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {stock_symbol}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(price_data) < 2:\n",
    "        print(\"Error: Need at least 2 stocks with sufficient data\")\n",
    "        return nx.Graph()\n",
    "    \n",
    "    # Create DataFrame with all stock prices aligned by date\n",
    "    combined_df = pd.DataFrame(price_data)\n",
    "    \n",
    "    # Remove any rows with NaN values\n",
    "    return combined_df#.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30460b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stock_correlation_network(stock_data_dict, n_days, correlation_threshold=0.0,output='graph',transformation='log'):\n",
    "    \"\"\"\n",
    "    Calculate pairwise Pearson correlations between stocks over the last n days\n",
    "    and return a NetworkX graph object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    stock_data_dict : dict\n",
    "        Dictionary where keys are stock symbols and values are DataFrames\n",
    "        with MultiIndex columns ('Close', stock_symbol) for price data\n",
    "    n_days : int\n",
    "        Number of recent days to use for correlation calculation\n",
    "    correlation_threshold : float, optional\n",
    "        Minimum correlation value to include an edge in the network (default: 0.0)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    networkx.Graph\n",
    "        Graph where nodes are stock symbols and edges represent correlations\n",
    "        Edge weights are the correlation coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_df=_organise_price_data(stock_data_dict, n_days)\n",
    "    if len(combined_df) < 2:\n",
    "        print(\"Error: Insufficient overlapping data points after removing NaN values\")\n",
    "        return None\n",
    "    if transformation=='log':\n",
    "        df=log_change(combined_df)#.dropna()\n",
    "    elif transfomration=='percent':\n",
    "        df=pct_change(combined_df)\n",
    "    else:\n",
    "        df=combined_df\n",
    "\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df.corr()\n",
    "    if output=='graph':\n",
    "        # Create NetworkX graph\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add nodes (stock symbols)\n",
    "        G.add_nodes_from(correlation_matrix.index)\n",
    "        \n",
    "        # Add edges with correlation weights\n",
    "        for stock1, stock2 in combinations(correlation_matrix.index, 2):\n",
    "            correlation = correlation_matrix.loc[stock1, stock2]\n",
    "            \n",
    "            # Only add edge if correlation meets threshold and is not NaN\n",
    "            if not pd.isna(correlation) and abs(correlation) >= abs(correlation_threshold):\n",
    "                G.add_edge(stock1, stock2, weight=correlation, correlation=correlation)\n",
    "        \n",
    "        # Add node attributes with some basic stats\n",
    "        for stock in G.nodes():\n",
    "            recent_prices = price_data[stock]\n",
    "            G.nodes[stock]['mean_price'] = recent_prices.mean()\n",
    "            G.nodes[stock]['std_price'] = recent_prices.std()\n",
    "            G.nodes[stock]['data_points'] = len(recent_prices)\n",
    "        \n",
    "        return G\n",
    "    else:\n",
    "        return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc27f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlation_network(G, top_n=5):\n",
    "    \"\"\"\n",
    "    Helper function to analyze the correlation network\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : networkx.Graph\n",
    "        The correlation network graph\n",
    "    top_n : int\n",
    "        Number of top correlations to display\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with network analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(G.edges()) == 0:\n",
    "        return {\"message\": \"No edges in the network\"}\n",
    "    \n",
    "    # Get edge weights (correlations)\n",
    "    correlations = [G[u][v]['correlation'] for u, v in G.edges()]\n",
    "    \n",
    "    # Sort edges by absolute correlation value\n",
    "    sorted_edges = sorted(G.edges(data=True), \n",
    "                         key=lambda x: abs(x[2]['correlation']), \n",
    "                         reverse=True)\n",
    "    \n",
    "    analysis = {\n",
    "        'num_nodes': G.number_of_nodes(),\n",
    "        'num_edges': G.number_of_edges(),\n",
    "        'avg_correlation': sum(correlations) / len(correlations),\n",
    "        'max_correlation': max(correlations),\n",
    "        'min_correlation': min(correlations),\n",
    "        'top_correlations': []\n",
    "    }\n",
    "    \n",
    "    # Get top correlations\n",
    "    for i, (stock1, stock2, data) in enumerate(sorted_edges[:top_n]):\n",
    "        analysis['top_correlations'].append({\n",
    "            'stocks': (stock1, stock2),\n",
    "            'correlation': data['correlation']\n",
    "        })\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_series_stock_correlations(stock_data_dict: Dict[str, pd.DataFrame], \n",
    "#                                       reference_series: pd.Series,\n",
    "#                                       n_days: int,\n",
    "#                                       reference_symbol: str = None,\n",
    "#                                       min_periods: int = 10,\n",
    "#                                       return_pvalues: bool = False) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculate Pearson correlations between a reference series and each stock \n",
    "#     in the dictionary over the last n days.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     stock_data_dict : dict\n",
    "#         Dictionary where keys are stock symbols and values are DataFrames\n",
    "#         with MultiIndex columns ('Close', stock_symbol) for price data\n",
    "#     reference_series : pd.Series\n",
    "#         Reference series to correlate against (e.g., market index, benchmark stock)\n",
    "#         Should have datetime index and numeric values\n",
    "#     n_days : int\n",
    "#         Number of recent days to use for correlation calculation\n",
    "#     reference_symbol : str, optional\n",
    "#         Symbol name for the reference series (for identification)\n",
    "#     min_periods : int, optional\n",
    "#         Minimum number of overlapping periods required (default: 10)\n",
    "#     return_pvalues : bool, optional\n",
    "#         Whether to return p-values along with correlations (default: False)\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     pd.Series or tuple\n",
    "#         If return_pvalues=False: Series with stock symbols as index and correlations as values\n",
    "#         If return_pvalues=True: Tuple of (correlations_series, pvalues_series)\n",
    "#     \"\"\"\n",
    "#     combined_df=_organise_price_data(stock_data_dict, n_days)\n",
    "   \n",
    "            \n",
    "#             if len(stock_recent) < min_periods:\n",
    "#                 print(f\"Warning: {stock_symbol} has only {len(stock_recent)} days of data\")\n",
    "#                 correlations[stock_symbol] = np.nan\n",
    "#                 if return_pvalues:\n",
    "#                     pvalues[stock_symbol] = np.nan\n",
    "#                 continue\n",
    "            \n",
    "#             # Align the series by their indices (dates)\n",
    "#             aligned_data = pd.DataFrame({\n",
    "#                 'reference': reference_recent,\n",
    "#                 'stock': stock_recent\n",
    "#             }).dropna()\n",
    "            \n",
    "#             if len(aligned_data) < min_periods:\n",
    "#                 print(f\"Warning: Only {len(aligned_data)} overlapping periods for {stock_symbol}\")\n",
    "#                 correlations[stock_symbol] = np.nan\n",
    "#                 if return_pvalues:\n",
    "#                     pvalues[stock_symbol] = np.nan\n",
    "#                 continue\n",
    "            \n",
    "#             # Calculate Pearson correlation\n",
    "#             if return_pvalues:\n",
    "#                 from scipy.stats import pearsonr\n",
    "#                 corr, p_val = pearsonr(aligned_data['reference'], aligned_data['stock'])\n",
    "#                 correlations[stock_symbol] = corr\n",
    "#                 pvalues[stock_symbol] = p_val\n",
    "#             else:\n",
    "#                 corr = aligned_data['reference'].corr(aligned_data['stock'])\n",
    "#                 correlations[stock_symbol] = corr\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {stock_symbol}: {e}\")\n",
    "#             correlations[stock_symbol] = np.nan\n",
    "#             if return_pvalues:\n",
    "#                 pvalues[stock_symbol] = np.nan\n",
    "#             continue\n",
    "    \n",
    "#     # Create result series\n",
    "#     corr_series = pd.Series(correlations, name=f'Correlation_with_{reference_symbol or \"Reference\"}')\n",
    "#     corr_series.index.name = 'Stock_Symbol'\n",
    "    \n",
    "#     if return_pvalues:\n",
    "#         pval_series = pd.Series(pvalues, name=f'P_Value_with_{reference_symbol or \"Reference\"}')\n",
    "#         pval_series.index.name = 'Stock_Symbol'\n",
    "#         return corr_series, pval_series\n",
    "    \n",
    "#     return corr_series\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
