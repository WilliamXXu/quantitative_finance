{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2f0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e49621f",
   "metadata": {},
   "source": [
    "Welcome to the Cointegration Challenge!\n",
    "Welcome, to an intriguing journey into the world of cointegration and pairs trading in quantitative finance. Cointegration is a statistical phenomenon that uncovers long-term equilibrium relationships between time series variables, playing a vital role in strategies such as pairs trading, risk management, and portfolio optimization.\n",
    "\n",
    "As we delve into this challenge, we will not only unravel the theory behind cointegration but also its practical implications in real-world finance. Our focus will be on mastering cointegration in the context of pairs trading, a market-neutral strategy that capitalises on the historical co-movement of assets. Pairs trading involves identifying and leveraging the relationship between two historically correlated assets, where their combined position is designed to be broadly market-neutral.\n",
    "\n",
    "Here is where cointegration becomes a game-changer. Unlike correlation, which merely indicates the tendency of assets to move together, cointegration suggests a deeper, more stable relationship. In the realm of non-stationary time series data, which is characteristic of most financial markets, cointegration provides a more robust and statistically significant framework. This is vital in pairs trading, as it allows us to identify pairs of assets whose price movements are not just temporarily aligned but are likely to converge in the long run, despite short-term deviations. Learn more about Cointegration here.\n",
    "\n",
    "Throughout this challenge, you will harness the power of Python and leverage essential libraries like pandas, numpy, and statsmodels to dissect, analyze, and model cointegrated time series.\n",
    "\n",
    "Challenge Overview\n",
    "OLS Regression: Conduct an Ordinary Least Squares (OLS) regression, where the first difference of the series is regressed against its value and any differences. This aims to understand the relationship between the changes in the series and its past values.\n",
    "\n",
    "Augmented Dickey-Fuller: Implement the Augmented Dickey-Fuller (ADF) test in order to determine the test statistic. This measures the importance of the level in explaining the changes in the series.\n",
    "\n",
    "Trading Bounds Analysis: Determine the upper and lower trading bounds from the residuals, essential for developing a pairs trading strategy.\n",
    "\n",
    "Application Across Three Rounds:\n",
    "\n",
    "Round 1: Apply your newfound knowledge to an initial dataset, analyzing results and making trading decisions.\n",
    "Round 2: Fine-tune your approach on a new unseen dataset, refining your strategy based on initial insights.\n",
    "Round 3: Test your refined strategy on a new, unseen dataset, putting your skills to the ultimate test.\n",
    "Assets Overview\n",
    "You will have access to the following assets throughout the challenge.\n",
    "\n",
    "Celestial Tech Enterprises (CTEN)\n",
    "Oceanic Trade Networks (OTNW)\n",
    "Zephyr Mobility Group (ZMG)\n",
    "Etherwave Communications (ETWC)\n",
    "Apex BioSolutions Inc. (ABSI)\n",
    "Pinnacle Finance Collective (PFNC)\n",
    "Infinite Realm Interactive (IRIN)\n",
    "Cybernex Software Corp. (CNSC)\n",
    "Pixelstream Graphics Ltd. (PXGL)\n",
    "Starbound Motors Corp. (SBMC)\n",
    "Whether you are a beginner or have experience in data science, this challenge will offer valuable insights into the practical application of cointegration in financial strategies. You will learn, experiment, and apply these concepts in a hands-on environment, preparing you for real-world quantitative finance challenges.\n",
    "\n",
    "Happy coding, and may your analytical skills flourish! Throughout the notebook you will find some cells cannot be edited and they are locked to form the foundations for you to work around them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following are private packages available only during this simulation:\n",
    "from AmplifyQuantTrading import Data\n",
    "from AmplifyArbitrageTrading.TradingEngine import TradingEngine, trading_engine_status, trading_engine_submission\n",
    "\n",
    "# The following are publicly available packages:\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports for OLS Regression Analysis\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Imports for ADF Test\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f96522",
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_id = 25831\n",
    "\n",
    "# Prices to be used throughout the Simulation\n",
    "historical_prices = Data.get_historical_price_series_for_round(portal_id, is_dataframe=True)\n",
    "trading_engine_status(portal_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6251fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Grid\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "tickers = historical_prices.columns\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ax = axes[i//2, i%2]\n",
    "    historical_prices[ticker].plot(ax=ax, title=ticker)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac0ca8",
   "metadata": {},
   "source": [
    "# OLS Regression Analysis: Exploring the Relationship between two assets.\n",
    "\n",
    "In financial econometrics, understanding the relationship between two time series, especially their linear interdependence, can be pivotal. One of the primary tools for this purpose is the Ordinary Least Squares (OLS) regression. The OLS method minimizes the sum of the squared differences between the observed and estimated values.\n",
    "\n",
    "Given two assets, we aim to determine if there exists a linear relationship between them. This relationship can be represented by:\n",
    "\n",
    "$$ Y_t = \\alpha + \\beta x_t + \\epsilon_t $$\n",
    "\n",
    "\n",
    "Where:\n",
    "* Y = Represents the price of Asset 1 at time t, now as the dependent variable.\n",
    "* X = Represents the price of Asset 2 at time t, now as the independent variable.\n",
    "* α is the intercept term.\n",
    "* β is the slope coefficient, representing the change in Asset 1's price for a unit change in Asset 2's price.\n",
    "* ϵ is the error term at time t, capturing all other factors affecting Asset 1's price that are not explained by Asset 2's price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = historical_prices[\"CTEN\"] # Dependent variable.\n",
    "X = historical_prices[\"CNSC\"] # Independent variable.\n",
    "X = sm.add_constant(X) # Independent variable with constant.\n",
    "\n",
    "# Perform OLS regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c469023",
   "metadata": {},
   "source": [
    "Using the statsmodels library, we’ve performed an OLS regression to understand the linear relationship between the assets. The following are the key results:\n",
    "\n",
    "1. **Intercept (Alpha)**:\n",
    "* This value represents the expected value of Asset 1 when Asset 2 is zero. It’s the point where the regression line crosses the Y-axis.\n",
    "\n",
    "2. **Slope (Beta)**:\n",
    "* This coefficient represents the change in Asset 1 for a unit change in Asset 2.\n",
    "\n",
    "3. **R-squared**:\n",
    "* This metric provides the proportion of the variance in the dependent variable (Asset 1) that’s predictable from the independent variable (Asset 2). An R-squared of 0.333 suggests that approximately 33.3% of the variability in Asset 1 can be explained by Asset 2.\n",
    "\n",
    "4. **Durbin-Watson**:\n",
    "* This test statistic tests for the presence of autocorrelation in the residuals. A value close to 2 suggests no autocorrelation, while a value that is far from 2, indicating possible autocorrelation.\n",
    "\n",
    "5. **Condition Number**:\n",
    "* A high value suggests potential multicollinearity issues or other numerical problems.\n",
    "\n",
    "### Implement OLS Regression for the other pairs.\n",
    "\n",
    "In the section below you can use the ```sm.OLS(y, X).fit()``` to check for the other assets being used in this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090c6e3",
   "metadata": {},
   "source": [
    "<img src=\"https://algo-assets.amplifyme.com/quant/gresearch/GResearch_Cointegration_C2.png\" width=\"100%\"/>\n",
    "\n",
    "## Spread and Its Significance in Pairs Trading\n",
    "\n",
    "In pairs trading, the spread is a pivotal concept. It quantifies the deviation of the relationship between two assets from their historical mean. When the spread substantially diverges from this mean, trading opportunities might emerge.\n",
    "\n",
    "\n",
    "The spread is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Spread} = X - (\\alpha + \\beta \\times Y)\n",
    "$$\n",
    "\n",
    "Here: \n",
    "* X = Asset 1\n",
    "* Y = Asset 2\n",
    "* α represents the intercept from our OLS regression. \n",
    "* β denotes the slope or hedge ratio from our OLS regression.\n",
    "\n",
    "\n",
    "The spread, in essence, captures the residuals of our regression model. It signifies the difference between the actual price of Asset 1 and its predicted value based on the price of Asset 2.\n",
    "\n",
    "## Visualising Residuals for Spread Trading\n",
    "\n",
    "It’s essential to compute the residuals to be used for trading. These residuals represent the deviations between the observed price of Asset 1 and its predicted value based with the Asset 2 prices.\n",
    "\n",
    "Residuals are an integral part of pairs trading. They encapsulate the temporary mispricings or deviations from the established relationship between the two assets, which are the trading opportunities we aim to exploit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "X_const = sm.add_constant(historical_prices[\"CNSC\"])\n",
    "model = sm.OLS(historical_prices[\"CTEN\"], X_const).fit()\n",
    "residuals = model.resid\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(residuals, label='Residuals', color='blue')\n",
    "plt.axhline(residuals.mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.title('Residuals Over Time with Mean')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56e3a0",
   "metadata": {},
   "source": [
    "## Augmented Dickey-Fuller Test\n",
    "\n",
    "The Augmented Dickey-Fuller (ADF) test is a prominent unit root test used to diagnose the stationarity of a given time series. A time series is deemed stationary if its statistical attributes (such as mean and variance) do not alter over time. For our pairs trading strategy, ascertaining stationarity is pivotal, as it ensures that the spread between the pairs is mean-reverting, allowing for potential arbitrage opportunities.\n",
    "\n",
    "#### Implementation Steps:\n",
    "1. **OLS Regression**:\n",
    "* An Ordinary Least Squares (OLS) regression was conducted where the first difference of the series was regressed against its value and any differences. The purpose is to capture the relationship between the changes in the series and its past values.\n",
    "\n",
    "2. **Test Statistic Calculation**:\n",
    "* The ADF test statistic was derived as the quotient of the coefficient of the level of the series and its standard error. This statistic gauges the significance of the level in explaining the changes in the series.\n",
    "\n",
    "3. **Comparison with Critical Values**:\n",
    "* To make an inference regarding stationarity, the computed test statistic is contrasted against predefined critical values. If the statistic is less than the critical value (often at 1%, 5%, or 10% significance levels), the null hypothesis of a unit root (implying non-stationarity) is rejected, signaling that the series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(y):\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    # Using statsmodels to get the results\n",
    "    adf_result = adfuller(y, maxlag=0)\n",
    "    pvalue = adf_result[1]\n",
    "    critical_values = adf_result[4]\n",
    "    \n",
    "    print(f\"ADF Statistic (statsmodels): {adf_result[0]}\")\n",
    "    print(f\"p-value: {pvalue:.10f}\")\n",
    "    for key, value in critical_values.items():\n",
    "        print(f\"Critical Value ({key}): {value}\")\n",
    "\n",
    "adf_test(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda00fa",
   "metadata": {},
   "source": [
    "<img src=\"https://algo-assets.amplifyme.com/quant/gresearch/GResearch_Cointegration_C3.png\" width=\"100%\"/>\n",
    "\n",
    "## Trading Bounds Analysis\n",
    "\n",
    "Pairs trading is predicated on the belief that if two co-integrated securities drift apart in terms of price, they will eventually revert back to a mean. The strategy thus revolves around identifying deviations from this mean and capitalizing on the expected mean reversion.\n",
    "\n",
    "1. **Long Signal**:\n",
    "\n",
    "This arises when the spread (or the residuals) dips below a predetermined lower threshold. A low spread indicates that, relative to its counterpart, the primary asset (as per our regression) is undervalued. In response, we should:\n",
    "\n",
    "* Long the primary asset (believing its price will rise).\n",
    "* Short the secondary asset (anticipating a price drop).\n",
    "\n",
    "$$\n",
    "\\text{Spread}_t < \\text{Lower Bound} \\Rightarrow \\text{Long Asset 1, Short Asset 2}\n",
    "$$\n",
    "\n",
    "2. **Short Signal**:\n",
    "\n",
    "This is activated when the spread exceeds a predetermined upper threshold. A high spread signifies that the primary asset is overpriced relative to the secondary asset. Consequently, we should:\n",
    "\n",
    "* Short the primary asset (anticipating its price will fall).\n",
    "* Long the secondary asset (believing its price will ascend).\n",
    "\n",
    "$$\n",
    "\\text{Spread}_t > \\text{Upper Bound} \\Rightarrow \\text{Short Asset 1, Long Asset 2}\n",
    "$$\n",
    "\n",
    "\n",
    "3. **Exit Signal (Neutralize):**\n",
    "\n",
    "This signal prompts us to close out any positions and return to a neutral stance. It’s initiated when the spread converges back towards its mean, hinting at the assets reverting to their equilibrium relationship. This is our cue to capitalize on the positions we’ve taken based on the long/short signals and secure our gains.\n",
    "\n",
    "$$ \n",
    "\\text{Lower Bound} \\leq \\text{Spread}_t \\leq \\text{Upper Bound} \\Rightarrow \\text{Exit Positions}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc921b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(residuals, Z, price_data_index, show_graph=True): # Generate bounds\n",
    "    mu_e = residuals.mean()\n",
    "    sigma_eq = residuals.std()\n",
    "    upper_bound = mu_e + Z * sigma_eq\n",
    "    lower_bound = mu_e - Z * sigma_eq\n",
    "    if not isinstance(residuals, pd.Series):\n",
    "        residuals_series = pd.Series(residuals, index=price_data_index)\n",
    "    else:\n",
    "        residuals_series = residuals\n",
    "    \n",
    "    # Generate signals\n",
    "    signals = pd.Series(index=residuals_series.index, dtype='float64') \n",
    "    signals[residuals_series > upper_bound] = -1 # Short signal signals[residuals_series < lower_bound] = 1 # Long signal\n",
    "    signals = signals.fillna(0) # Fill NaN values with 0\n",
    "    if show_graph:\n",
    "        plt.figure(figsize=(14,7))\n",
    "        residuals_series.plot(label='Residuals')\n",
    "        plt.axhline(upper_bound, color='red', linestyle='--', label='Upper Bound')\n",
    "    plt.axhline(lower_bound, color='green', linestyle='--', label='Lower Bound')\n",
    "    plt.axhline(0, color='blue', linestyle='-') \n",
    "    plt.title('Residuals with Long and Short Signals') \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return upper_bound, lower_bound, residuals_series\n",
    "\n",
    "upper_bound, lower_bound, residuals_series = generate_signals(residuals, 1, historical_prices.index[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7641a0c",
   "metadata": {},
   "source": [
    "<img src=\"https://algo-assets.amplifyme.com/quant/gresearch/GResearch_Cointegration_C4.png\" width=\"100%\"/>\n",
    "\n",
    "## Trading Application \n",
    "\n",
    "Backtesting is a cornerstone of algorithmic trading. Before deploying a strategy in real-time, it’s imperative to understand how it would have performed historically. This process involves simulating trades based on past data and analyzing the results to evaluate the strategy’s robustness, potential profitability, and associated risks. In this section, we will immerse ourselves in the intricacies of backtesting, ensuring that our strategy is not just theoretically sound but also practical and viable in real-world scenarios. By understanding its historical behavior, we can make more informed decisions about its future deployment.\n",
    "\n",
    "#### Class TradingEngine\n",
    "\n",
    "The engine class is used to simulate a high-frequency trading strategy. It contains the following properties:\n",
    "\n",
    "* balance (float): The balance of the trading account, in dollars.\n",
    "* profit_loss (float): The profit and loss of the trading account, in dollars.\n",
    "* profit_loss_without_commission (float): The profit and loss without the commission deductions, in dollars.\n",
    "* current_positions (dict): A dictionary of CurrentPosition objects, with each key representing a different asset.\n",
    "* commission_costs (float): The commission costs in dollars.\n",
    "* commission_percentage (float): The commission percentage to be applied to each trade, expressed\n",
    "\n",
    "##### **Functions**\n",
    "\n",
    "```python\n",
    "execute_order(self, ticker: str, volume: int, action: str, date: int)\n",
    "```\n",
    "This function allows the execution of a trade order for a specific stock represented by ticker.\n",
    "\n",
    "*Parameters:*\n",
    "* ticker: a string representing the stock's ticker symbol. The symbol will be automatically converted to uppercase.\n",
    "* volume: an integer representing the number of shares to be traded.\n",
    "* action: a string representing the type of order to be executed. Acceptable values are BUY or SELL. The action will be automatically converted to uppercase.\n",
    "* date: an integer representing the date of the trade.\n",
    "\n",
    "*Returns:*\n",
    "Based on the current position of the stock and the action provided, the function will determine the trade to be executed. If the function fails to execute you will see an error is raised.\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### Class CurrentPosition\n",
    "\n",
    "The CurrentPosition class is used to track and manage the positions taken by the engine object. It contains the following properties:\n",
    "\n",
    "* ticker (str): The ticker symbol of the asset being traded.\n",
    "* direction (str): The direction of the trade, either \"LONG\", \"SHORT\", or \"FLAT\".\n",
    "* position_volume (int): The number of shares held in the current position.\n",
    "* open_price (float): The price at which the position was opened.\n",
    "* profit_loss (float): The profit or loss in dollars, calculated as the difference between the open price and the current price.\n",
    "* profit_loss_without_commission (float): The profit or loss in dollars without the commission deductions.\n",
    "* commission_costs (float): The cumulative commission costs for this position.\n",
    "* trade_history (list): A list of dictionaries, each representing a single trade in this position.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e667f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below creates the Trading Engine object\n",
    "live_prices = Data.get_price_series_for_round(portal_id, is_dataframe=True)\n",
    "engine = TradingEngine(commission_percentage=0.005, data=live_prices)\n",
    "trading_engine_status(portal_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def template_strategy(tickers, date):    \n",
    "    # Insert your answer code here\n",
    "    \n",
    "    # Randomly select a ticker\n",
    "    ticker = random.choice(tickers)\n",
    "\n",
    "    # Randomly decide whether to buy or sell\n",
    "    action = random.choice([\"BUY\", \"SELL\"])\n",
    "\n",
    "    # Randomly select a volume to trade\n",
    "    volume_to_trade = random.randint(1, 10)\n",
    "\n",
    "    try:\n",
    "        # Place trades in the trading engine\n",
    "        engine.execute_order(ticker, volume_to_trade, action, date)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to execute order for {ticker} on {date}: {e}\")\n",
    "        \n",
    "    return ticker, volume_to_trade, action\n",
    "\n",
    "tickers = live_prices.columns.tolist()\n",
    "for date, _ in live_prices.iterrows():\n",
    "    # Use the random trading strategy\n",
    "    template_strategy(tickers, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_strategy(tickers, date):    \n",
    "    threshold=0.05\n",
    "    Z=1\n",
    "    amount_to_trade=20000000/100\n",
    "    reversal_threshold=1\n",
    "    initial_threshold=1.5\n",
    "    print(date)\n",
    "    if date >10000:        \n",
    "        df=live_prices.loc[live_prices.index<=date,]\n",
    "        trade_book=dict()\n",
    "        res={'adf_test':dict(),'residuals':dict(),'strength':dict()}\n",
    "        for i, ticker in enumerate(tickers):\n",
    "            for j,ticker1 in enumerate(tickers):\n",
    "                if j!=i:\n",
    "                    #print(ticker)\n",
    "                    #print(ticker1)\n",
    "                    X_const = sm.add_constant(df.loc[:,ticker])\n",
    "                    model = sm.OLS(df.loc[:,ticker1], X_const).fit()\n",
    "                    residuals = model.resid\n",
    "                    res['residuals'][ticker+' '+ticker1]=residuals\n",
    "                    #res[ticker+' '+ticker1]={'residuals':residuals}\n",
    "                    adf=adf_test(residuals)#\n",
    "                    res['adf_test'][ticker+' '+ticker1]=adf\n",
    "        #adf_test_res=pd.Series(res['adf_test'])#.min()\n",
    "\n",
    "        for dic in current_pairs:\n",
    "            ticker=dic['ticker']\n",
    "            ticker1=dic['ticker1']\n",
    "            volume=dic['volume']\n",
    "            volume1=dic['volume1']\n",
    "            direction=dic['dir']\n",
    "            print(engine.current_positions)\n",
    "            if signal_strength(res['residuals'][ticker+' '+ticker1])<reversal_threshold:\n",
    "                if direction:\n",
    "                    engine.execute_order(ticker,volume,'BUY', date)\n",
    "                    engine.execute_order(ticker1, volume1, 'SELL', date)\n",
    "                else:\n",
    "                    engine.execute_order(ticker1, volume1,'BUY', date)\n",
    "                    engine.execute_order(ticker, volume, 'SELL', date)\n",
    "        \n",
    "        for k,v in res['adf_test'].items():\n",
    "            if v<threshold:\n",
    "                res['strength'][k]=signal_strength(res['residuals'][k])\n",
    "        if len(res['strength'])>0:\n",
    "            res['strength']=pd.Series(res['strength'])\n",
    "            if res['strength'].abs().max()>initial_threshold:\n",
    "                pair=res['strength'].abs().idxmax()\n",
    "                direction=(res['strength'].loc[pair]>0)\n",
    "                ticker,ticker1=pair.split(' ')\n",
    "                #print(ticker)\n",
    "                #print(ticker1)\n",
    "                #print(direction)\n",
    "                volume= int(amount_to_trade/df.loc[:,ticker].iloc[-1])\n",
    "                volume1=int(amount_to_trade/df.loc[:,ticker1].iloc[-1])\n",
    "                print(volume)\n",
    "                print(volume1)\n",
    "                if direction:\n",
    "                    engine.execute_order(ticker,volume,'BUY', date)\n",
    "                    engine.execute_order(ticker1, volume1, 'SELL', date)\n",
    "                else:\n",
    "                    engine.execute_order(ticker1, volume1,'BUY', date)\n",
    "                    engine.execute_order(ticker, volume, 'SELL', date)\n",
    "                current_pairs.append({'ticker':ticker,'volume':volume,'ticker1':ticker1,'volume1':volume1,'dir':direction})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d87032",
   "metadata": {},
   "source": [
    "<img src=\"https://algo-assets.amplifyme.com/quant/gresearch/GResearch_Cointegration_Appendix.png\" width=\"100%\"/>\n",
    "\n",
    "# Python 3.10.10 Documentation\n",
    "[Checkout the documentation](https://docs.python.org/release/3.10.10/)\n",
    "\n",
    "[What is new in Python 3.10](https://docs.python.org/3/whatsnew/3.10.html)\n",
    "\n",
    "[Differences between Python 3 and Python 2](https://www.ibm.com/docs/en/sqsp/48?topic=scripts-python-2-python-3-differences)\n",
    "\n",
    "# Import Explanations\n",
    "\n",
    "## Publicly Available Packages\n",
    "\n",
    "1. **Matplotlib**\n",
    "   ```python\n",
    "   from matplotlib import pyplot as plt\n",
    "   ```\n",
    "   - Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. The `pyplot` module provides a MATLAB-like interface for making plots and graphs.\n",
    "\n",
    "2. **Pandas**\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   ```\n",
    "   - Pandas is a fast, powerful, flexible, and easy-to-use open-source data analysis and manipulation tool, built on top of the Python programming language. It offers data structures like DataFrame for handling tabular data.\n",
    "\n",
    "3. **NumPy**\n",
    "   ```python\n",
    "   import numpy as np\n",
    "   ```\n",
    "   - NumPy is the fundamental package for scientific computing with Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "\n",
    "4. **SciPy Stats**\n",
    "   ```python\n",
    "   import scipy.stats as stats\n",
    "   ```\n",
    "   - SciPy is a Python-based ecosystem of open-source software for mathematics, science, and engineering. The `stats` module in SciPy contains a large number of probability distributions as well as a growing library of statistical functions.\n",
    "\n",
    "5. **Seaborn**\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   ```\n",
    "   - Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "## Imports for OLS Regression Analysis\n",
    "\n",
    "1. **Statsmodels for Statistical Modeling**\n",
    "   ```python\n",
    "   import statsmodels.api as sm\n",
    "   ```\n",
    "   - Statsmodels is a Python module that provides classes and functions for the estimation of many statistical models, as well as for conducting statistical tests, and statistical data exploration. In the context of Ordinary Least Squares (OLS) regression analysis, `sm` from Statsmodels is used for fitting linear models, performing tests, and exploring data.\n",
    "\n",
    "## Imports for ADF Test\n",
    "\n",
    "1. **Statsmodels for Time Series Analysis**\n",
    "   ```python\n",
    "   from statsmodels.tsa.stattools import adfuller\n",
    "   ```\n",
    "   - Statsmodels provides classes and functions for the estimation of many different statistical models. `adfuller` is used for the Augmented Dickey-Fuller test, a type of statistical test called a unit root test, essential in time series analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
